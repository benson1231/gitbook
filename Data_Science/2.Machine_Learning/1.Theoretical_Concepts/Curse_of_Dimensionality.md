# Curse of Dimensionality

維度詛咒（Curse of Dimensionality）是指隨著資料維度（特徵數量）增加，資料分析與建模變得越來越困難的現象。這是機器學習與資料探勘中一個經常面對的挑戰。

---

## 1. 問題來源
- 資料點在高維空間中會變得非常稀疏
- 距離度量失效：在高維空間中，資料點之間的距離差異變得不明顯，導致像 KNN、SVM 這類依賴距離的模型效果變差
- 維度增加會導致模型需要指數級資料量來保持泛化能力 → 模型容易過擬合

---

## 2. 實際影響
### A. 分類與回歸模型表現不穩定
- 高維資料導致模型學習雜訊而非模式
- 訓練資料不足以涵蓋所有可能組合 → 泛化差

### B. 資料視覺化困難
- 無法直接在 2D/3D 中觀察資料結構
- 降維後可能失去某些資訊

### C. 相似度計算無效
- 在高維空間中，最大與最小距離的比例趨近於 1 → 無法區分近與遠的樣本

---

## 3. 對策與解法
### 降維（Dimensionality Reduction）
- **PCA / t-SNE / UMAP**：將資料映射到較低維空間以保留主要變異
- **Autoencoder**：神經網路方式進行特徵壓縮

### 特徵選擇（Feature Selection）
- 移除不相關或冗餘的特徵，保留有助模型預測的部分
- 可搭配 Lasso、RFE、基於樹的特徵重要性

### 建模策略調整
- 使用對高維更穩定的模型（如樹模型、嵌入式模型）
- 增加資料量或使用正則化防止過擬合

---

## 4. 數學直覺（舉例）
在一個 1 維區間 [0,1] 中，100 個點已很密集。但若換到 10 維空間的 [0,1]^10，這 100 個點在體積為 1 的空間中分布就極度稀疏。

換句話說：維度每多 1，資料點需求量呈指數成長。

---

## 5. 小結
| 問題               | 原因                           | 解法                         |
|--------------------|--------------------------------|------------------------------|
| 模型過擬合         | 特徵太多，樣本太少              | 特徵選擇、正則化、收集更多資料 |
| 計算資源消耗大     | 高維空間複雜度高                | 降維、精簡模型結構             |
| 分群/距離無效      | 距離集中現象                   | 使用核技巧、改用角度相似度     |

---

維度詛咒提醒我們「特徵不是越多越好」，尤其在樣本數有限時，更應關注特徵的品質與代表性，而非盲目堆疊維度。
