# Dimensionality Reduction

降維（Dimensionality Reduction）是一種將高維資料轉換為較低維度表示的技術，其目的是在保留重要資訊的同時，減少計算負擔、消除雜訊、促進視覺化或提升模型效能。

---

## 1. 為什麼要降維？
- **資料視覺化**：將高維度資料轉為 2D 或 3D，幫助人眼觀察結構與群集
- **避免維度詛咒（curse of dimensionality）**：高維資料會導致距離計算失真、模型過擬合
- **加快演算法效率**：減少特徵數量可提升訓練與推論速度
- **去除冗餘與雜訊特徵**

---

## 2. 降維方法分類

### A. 線性方法
- **PCA（主成分分析）**：透過最大化變異數找出資料主軸
- **LDA（線性判別分析）**：考慮類別資訊，找出分群最佳區分軸（屬於監督式降維）

### B. 非線性方法
- **t-SNE**：保留局部鄰近關係，適合群集視覺化
- **UMAP**：保留局部與全域結構，速度快、可用於後續建模

### C. 特徵選擇（非嵌入式降維）
- 透過 Wrapper / Filter / Embedded 方法選出重要特徵，雖不是轉換資料空間，但亦屬降維策略

---

## 3. 各方法比較
| 方法   | 類型     | 保留結構 | 可解釋性 | 可用於建模 | 適合視覺化 | 效率 |
|--------|----------|-----------|------------|------------------|------------------|--------|
| PCA    | 線性     | 全域       | 高         | 是               | 有限             | 高     |
| LDA    | 監督式   | 類別區分   | 中         | 是               | 有               | 中     |
| t-SNE  | 非線性   | 局部       | 低         | 否               | 高               | 低     |
| UMAP   | 非線性   | 局部+全域 | 中         | 是（部分）       | 高               | 高     |

---

## 4. 實務建議
- 若要進行視覺化 → 推薦使用 **t-SNE** 或 **UMAP**
- 若要降維後用於機器學習模型 → 優先考慮 **PCA** 或 **UMAP**
- 若資料已具標籤分類 → 可考慮 **LDA**（監督式降維）
- 若目的是刪除冗餘特徵 → 也可使用 Wrapper / Embedded 方法進行特徵選擇

---

## 5. 延伸學習
- 你可以在本章節後閱讀各降維方法的個別檔案：
  - `PCA.md`
  - `LDA.md`
  - `tSNE.md`
  - `UMAP.md`
