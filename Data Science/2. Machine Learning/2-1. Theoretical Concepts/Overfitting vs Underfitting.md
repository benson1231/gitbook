# Overfitting vs Underfitting

在機器學習中，模型效能的好壞往往與其是否「過擬合（Overfitting）」或「欠擬合（Underfitting）」有密切關聯。理解兩者差異是模型選擇與調整的重要基礎。

---

## 1. 欠擬合（Underfitting）

當模型太過簡單，無法捕捉資料中的模式時，即發生欠擬合。

### 特徵：

* 訓練誤差高，測試誤差也高
* 模型學習不到有效關係，準確度低
* 可能因模型太簡單或訓練不夠久

### 解法：

* 使用更複雜的模型（例如線性回歸 → 多項式回歸）
* 增加訓練時間或特徵
* 降低正則化強度

---

## 2. 過擬合（Overfitting）

當模型太過複雜，以致於不僅學習資料中的趨勢，也學到了雜訊，即為過擬合。

### 特徵：

* 訓練誤差極低，但測試誤差高
* 模型在新資料上表現不佳
* 對訓練資料過度記憶，泛化能力差

### 解法：

* 使用更簡單的模型
* 增加訓練資料量（資料擴增）
* 採用正則化（L1、L2）
* 使用交叉驗證進行模型選擇

---

## 3. 比較總結表

| 特徵   | 欠擬合        | 過擬合         |
| ---- | ---------- | ----------- |
| 訓練誤差 | 高          | 低           |
| 測試誤差 | 高          | 高           |
| 原因   | 模型太簡單、特徵不足 | 模型太複雜、學到雜訊  |
| 解法   | 增加模型複雜度、特徵 | 降低模型複雜度、正則化 |

---

良好的模型應該在訓練與測試資料上皆表現良好，達到最佳的「擬合平衡」。這也是交叉驗證與正則化等技巧存在的重要原因。
